\documentclass[12pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in]{geometry}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{amsmath}
\usepackage{amsfonts}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=black,
    urlcolor=black
}

\title{MAT292 Notes}
\date{September 2021}

\begin{document}

\maketitle
\tableofcontents

\section{Existence and Uniqueness Theorem}

\begin{enumerate}
    \item We need $f(t,y)$ continuous in the rectangle to get existence
    \item We need $f_y(t,y)$ continuous in the rectangle to get uniqueness
    \item E \& U Theorem is sufficient but not necessary. i.e. these conditions imply solution but not having these conditions doesnt mean there is no solution
\end{enumerate}

\section{Autonomous Equations and Population Dynamics}

\subsection{Logistic Growth}

If uninhibited, we assume exp. growth however in the long run,population is limited to $K$

Model: $y' = r h(y) y$

We want $h(y) \approx 1$ if $y$ is small, $h(y) < 1$ if $y < k$, $h(y) = 0 $ if $y=k$ and $h(y) < 0$ if $y>K$ 

This can thus be modelled as $y' = r(1 - \frac{y}{k})y$. This has two equilibria namely at $y=0$ and $yk$. The inflection points can be found by setting the derivative $y''$ to 0.

\section{Direction Fields and Orbits}

\subsection{Reducing non homogeneous systems to homogeneous systems}

Lets take a solution $x$ and write it as $x = \phi + v$ where $v$ is a constant. Then $x' = Ax + b \rightarrow \phi = A(\phi + v) + b$. Since $x_{eq} = A^{-1}b$, $Av+b =0$ by the equilibrium condition ($\phi' - A \phi$) we have that $\phi' = A \phi$. So that $x = \phi + x_{eq}$ where $\phi$ is a solution of the homogeneous system. 

Every solution of the non homogeneous problem can be written as a solution of the homogeneous problem plus the equilibrium. 

\section{Laplace Transform}

\begin{itemize}
    \item Remark: The laplace transform will allow us to reduce solving an ODE to solving an algebraic equation
    \item Solve algebraic equation and use the inverse laplace transform to get the solution to the ODE
    \item Definition: If $f$ is defined on $[0, \infty]$, the Laplace Transform is defined as $F(s) = \int_{0}^{\infty} e^{-st} f(t) \, dt$
    \item We write $F = \mathcal{L} \{f\}$
    \item We use uppercase letters for Laplace transform e.g. $G(s)$ is the LT of $g(t)$
    \item Example: For $f(t) = e^{at}$, we get $F(s) = \mathcal{L}\{f\}(s) = \int_{0}^{\infty} e^{-st} e^{at} \, dt = \lim_{b\rightarrow \infty} \int_{0}^{b} e^{(a-s)t} \, dt = \lim_{b\rightarrow \infty} \frac{1}{a-s} \left( e^{(a-s)b} - 1 \right) = \frac{1}{s-a}$ if $s > a$
    \item $\mathcal{L} \{1\} = \frac{1}{s}$
    \item Theorem: $\mathcal{L} \{c_1f_1 + c_2f_2\} = c_1 \mathcal{L} \{f_1\} + c_2 \mathcal{L} \{f_2\}$
    \item To find $\mathcal{L} \{\sin(at)\}$, write $\sin(at) = \frac{1}{2i} (e^{iat} - e^{-iat})$ and use the theorem above
    \item This will give $\frac{1}{2i} \left(\frac{1}{s - ia}\right) - \frac{1}{2i} \left(\frac{1}{s+ia}\right) = \frac{a}{s^2 + a^2}$ for $s > 0$
    \item Example: LT of $f(t) = e^{2t}$ for $0 \leq t < 1$ and $f(t) = 4$ for $1 \leq t$
    \item Divide the integral into two seperate parts and evaluate it
    \item Exponential order: A function $f(t)$ is of exponential order for $M > 0$, $K > 0$ and $a \in \mathbb{R} $ if $|f(t)| \leq Ke^{at}$ for $t \geq M$ i.e. $f$ eventually becomes between two exponential functions
    \item Theorem: Every bounded function is of exponential order
    \item A function $f(t)$ is piecewise continuous on $[a,b]$ iff there are finitely many "jump points" between $a$ and $b$ $a \leq t_0 < t_1 < \dots < t_{k-1} < t_k = b$ such that $f$ is continuous on each of the intervals $(t_i, t_{i+1})$ and $f$ has finite limits at the jump points.
    \item Theorem: If for a function $f(t)$, we have that $f$ is piecewise continuous on $[0, A]$ $\forall A \geq 0$ and $f$ is of exponential order for $M, k$ and $a$. Then $\mathcal{L} \{f\}$ exists for all $s > a$. 
    \item Theorem: If $f(t)$ is of exponential order then we have: $F(s) \rightarrow 0$ as $s \rightarrow \infty$ where $F(s)$ is the L.T. of $f$
    \item Theorem: If $f$ is continuous and $f'$ is piecewise continuous on any interval $[0, A]$ and $f, f'$ are of exponential order for $M, k, a$ then $\mathcal{L} \{f'\} (s) = s \mathcal{L} \{f\} (s) - f(0)$ for $s>a$. Under the same conditions for $n$ derivatives, $\mathcal{L} \{f^{(n)}\} (s) = s^n \mathcal{L} \{f\} (s) - s^{n-1} f(0) - s^{n-2} f'(0) - \dots sf^{(n-2)} (0) - f^{(n-1)} (0)$ 
    \item Proof: $\mathcal{L} \{f'\} (s) = \int_{0}^{\infty} e^{-st} f'(t) \, dt = \lim_{b \rightarrow \infty} \left(\int_{0}^{b} e^{-st} f'(t) \, dt \right) $
    
    $= \lim_{b \rightarrow \infty} \left( \left[ e^{-st} f(t) \right]_{0}^{b} + \int_{0}^{b} f(t) s e^{-st} \, dt \right) = \lim_{b \rightarrow \infty} \left( e^{-bs}f(b) - f(0) + s \int_{0}^{b} f(t) e^{-st} \, dt \right) $ 
    $= s \mathcal{L} \{f\} (s) - f(0)$ where $s > a$ (by definition of exponential order)
\end{itemize} 

\section{Inverse Laplace Transform}

\begin{itemize}
    \item Theorem: If $f(t), g(t)$ are piecewise continuous and of exponential order, then $\mathcal{L} \{f\} = \mathcal{L} \{g\} \implies f(t) = g(t)$
    \item Technicality: Take $f(t) = e^t$, $g(t) = \begin{cases} 
        e^t & t \neq 5 \\
        0 & t = 5  
     \end{cases}$. Clearly $\mathcal{L} \{f\} = \mathcal{L} \{g\}$ but $f(t) \neq g(t) \, \forall t$
     \item Convention: We write $f(t) = g(t)$ as long as they are the same whenever they are continuous
     \item Definition: If $f$ is piecewise continuous and of exponential order and $\mathcal{L} \{f\} (s) = F(s)$, then we call $f(t) = \mathcal{L}^{-1} \{F\} (t)$
     \item There is a complex analysis formula (Mellin Transform) to find $\mathcal{L}^{-1} \{F\}$. However this is rarely used in practice and we instead use tables
\end{itemize}

\section{Solving ODEs with Laplace Transform}
\begin{itemize}
    \item Lets solve the IVP $y'' + 2y' + 5y = e^{-t}$, $y(0) = 1$, $y'(0) = -3$ \begin{itemize}
        \item Use the Laplace transform: $\mathcal{L} \{y'' + 2y' + 5y\} = \mathcal{L} \{e^{-t} \}$
        \item $s^2 Y(s) - sy(0) - y'(0) + 2(sY(s) - y(0)) + 5Y(s) = \frac{1}{s+1}$
        \item $s^2 Y(s) - s \cdot 1 - (-3) + 2(sY(s) - 1) + 5 Y(s) = \frac{1}{s+1}$ using the initial conditions
        \item Solving this gives $Y(s) = \frac{s^2}{(s+1)(s^2+2s+5)}$
        \item Simplifying and using partial fractions, $Y(s) = \frac{1}{4} \frac{1}{s+1} + \frac{3}{4} \frac{s+1}{(s+1)^2 + 4} - \frac{2}{(s+1)^2 + 4}$
        \item $y(t) = \mathcal{L} ^{-1} \{Y(s) \} = \frac{1}{4} \mathcal{L} ^{-1} \{\frac{1}{s+1}\} + \frac{3}{4} \mathcal{L} ^{-1} \{\frac{s+1}{(s+1)^2+4}\} - 2 \mathcal{L}^{-1} \{ \frac{1}{(s+1)^2+4}\}$ 
        \item $ = \frac{1}{4} e^{-t} + \frac{3}{4} e^{-t} \cos (2t) - e^{-t} \sin (2t)$
    \end{itemize}
    \item Lets solve the IVP $y'''' + 2y' + y = 0$, $y(0) = 1$, $y'(0) = -1$, $y''(0) = 0$, $y'''(0) = 2$ \begin{itemize}
        \item Applying the Laplace transform: $s^4 Y(s) - s^3 y(0) - s^2 y'(0) - s y''(0) - y'''(0) + 2 (s^2 Y(s) - sy(0) - y'(0)) + Y(s) = 0$
        \item Using the initial conditions, $s^4 Y(s) - s^3 + s^2 - 2 + 2(s^2Y(s) - s + 1) + Y(s) = 0$
        \item Solving gives $Y(s) = \frac{s^3 - s^2 + 2s}{(s^2+1)^2}$
        \item We use a repeated partial fraction decomposition to write $Y(s)$ as $\frac{As+B}{s^2+1} + \frac{s+1}{(s^2+1)^2}$
        \item We know $y(t) = \mathcal{L} ^{-1} \{ \frac{s}{s^2+1} - \frac{1}{s^2+1} + \frac{s}{(s^2+1)^2} + \frac{1}{(s^2+1)^2} \}$
        \item For the third term, we use $\mathcal{L} \{t \cdot f(t) \} = \frac{-d}{ds} F(s)$ and then get $ y(t) = \cos t - \sin t + \frac{1}{2} t \sin t + \frac{1}{2} \sin t - \frac{1}{2} t \cos t $
    \end{itemize}
\end{itemize}

\section{Discontinuous Forcing Functions}

\begin{itemize}
    \item Finding $\mathcal{L} \{ t \} = \int_{0}^{\infty} e^{-st} t \, dt = \frac{1}{s^2}$ (IBP) or using $\mathcal{L} \{t\} = \mathcal{L} \{t \cdot 1 \}$ and $\mathcal{L} \{ t \cdot 1 \} = - \frac{d}{ds} (\frac{1}{s}) = \frac{1}{s^2}$
    \item Consider $y'' + 4y = g(t)$ with $y(0) = 0$, $y'(0) = 0$ and $g(t) = \begin{cases} 
        0 & 0 < t < 5 \\
        \frac{t-5}{5} & t = 5 \leq t < 10 \\
        t & 10 \leq t
     \end{cases}$ \begin{itemize}
         \item Can split it up into 3 parts and find relevant boundary conditions in each case to be used in the next case 
     \end{itemize}
     \item Piecewise defined functions can simulate the activation of a signal \begin{itemize}
         \item $u_c(t)$ is a step function that is 0 till $x = c$ and then 1 afterwards
         \item $u_{cd} (t)$ is an indicator function which is 1 between $c$ and $d$ and 0 everywhere else
         \item Use a combination of step and indicator functions $= u_{cd} (t) \frac{t-c}{d-c} + u_d(t)$ which is 0 less than $c$, increasing between $c$ and $d$ and 1 for values greater than $d$
     \end{itemize}
     \item We can find the Laplace transforms of these functions \begin{itemize}
         \item $\mathcal{L} \{ u_c \} = \int_{0}^{\infty} e^{-st} u_c(t) \, dt = \int_{c}^{\infty} e^{-st} \cdot 1 \, dt = \frac{e^{-cs}}{s}$
         \item $\mathcal{L} \{ u_{cd} \} = \mathcal{L} \{ u_c - u_d \} = \frac{e^{-cs}}{s} - \frac{e^{-ds}}{s}$
     \end{itemize}
     \item The function $g(t)$ from earlier can be written as $u_{5,10} (t) \cdot \frac{t-5}{5} + u_{10} (t) \cdot 1 $ \begin{itemize}
         \item Rearrange this as $\frac{1}{5} \left[ u_{5,10} (t) (t-5) + 5 u_{10} \right]  = \frac{1}{5} \left[ (u_5(t) - u_{10}(t))(t-5) + 5 u_{10} (t) \right] = \frac{1}{5} \left[ u_5(t) (t-5) - u_{10} (t) (t-10) \right]$
         \item $h(t) = u_5(t) (t-5)$ is the time shift of $f$ by $t = 5$
     \end{itemize}
     \item Theorem (Laplace transform of time-shift): If $F = \mathcal{L} \{f\}$ exists for $s > a$ and $c \geq 0$, then $\mathcal{L} \{ u_c(t) f(t-c) \} = \int_{0}^{\infty} e^{-st} u_c(t) f(t-c) \, dt = \int_{c}^{\infty} e^{-st} f(t-c) \, dt = \int_{0}^{\infty} e^{-s(u+c)} f(u) \, du = e^{-sc} \int_{0}^{\infty} e^{-su} f(u) \, du = e^{-sc} \mathcal{L} \{f\}$
     \item Consider the IVP $y(0) = 0$, $y'(0) = 0$ and $y'' + 4y = u_1(t)$ \begin{itemize}
         \item $\mathcal{L} \{y'' + 4y \} = \mathcal{L} \{ u_1(t) \} \rightarrow s^2Y(s) - sy(0) + 4Y(s) = \frac{e^{-s \cdot 1}}{s}$
         \item $(s^2 + 4) Y(s) = \frac{e^{-s}}{s} \rightarrow Y(s) = \frac{e^{-s}}{s(s^2+4)}$
         \item $Y(s) = e^{-s} \left( \frac{1}{4s} + \frac{-\frac{1}{4}s}{s^2+4} \right) = \frac{1}{4} e^{-s} \left( \frac{1}{s} - \frac{s}{s^2+4} \right)$ 
         \item Let $H(s) = \frac{1}{s} - \frac{s}{s^2+4}$ so that $h(t) = 1 - \cos (2t)$. $y(t) = \frac{1}{4} u_1(t) h(t-1)$ by the previous theorem 
     \end{itemize}
     \item Consider $y'' + 4y = g(t)$ with $y(0) = 0$, $y'(0) = 0$ and $g(t) = \begin{cases} 
        0 & 0 < t < 5 \\
        \frac{t-5}{5} & t = 5 \leq t < 10 \\
        t & 10 \leq t \end{cases}$ as before \begin{itemize}
            \item $g(t)$ is equivalent to $\frac{1}{5} ( u_5(t) (t-5) - u_{10}(t)(t-10))$
            \item $\mathcal{L} \{y'' + 4y \} = \mathcal{L} \{g(t) \} \rightarrow (s^2+4)Y(s) = \frac{1}{5} \left[ e^{-5s} \cdot \frac{1}{s^2} - e^{-10s} \cdot \frac{1}{s^2} \right]$
            \item $Y(s) = \frac{1}{5} \left[ e^{-5s} \frac{1}{s^2(s^2+4)} - e^{-10s} \frac{1}{s^2(s^2+4)} \right]$ so that $y(t) = \frac{1}{5} \left[ u_5(t) h(t-5) - u_{10}(t) h(t-10) \right]$ where $h(t) = \mathcal{L}^{-1} \{ \frac{1}{s^2(s^2+4)} \} = \frac{1}{4} t - \frac{1}{8} \sin(2t)$
        \end{itemize}
\end{itemize}

\section{Impulse Functions}

\begin{itemize}
    \item $\delta_{\epsilon} (t) = \frac{1}{\epsilon} \cdot [u_0(t) - u_{\epsilon}(t)]$
    \item Note: $\int_{0}^{\infty} \delta_{\epsilon}(t) \, dt = 1$
    \item Equivalently $\delta_{\epsilon}(t) = \begin{cases}
        \frac{1}{\epsilon} & 0 \leq t < \epsilon \\
        0 & \mathrm{else}
    \end{cases}$
    \item Let $\delta = \lim_{\epsilon \rightarrow 0} \delta$ such that $\delta(t) = 0$ when $t \neq 0$
    \item Then $\delta(t) = \begin{cases}
        \infty & t = 0 \\
        0 & t \neq 0
    \end{cases}$
    \item $\int_{0}^{\infty} \delta(t) \, dt = \lim_{\epsilon \rightarrow 0} 1 = 1$
    \item For any function $f(t)$ continuous on $a \leq 0 < b$, we have $\int_{a}^{b} f(t) \delta(t) \, dt = \lim_{\epsilon \rightarrow 0} \int_{a}^{b} f(t) \delta_{\epsilon} (t) \, dt = \lim_{\epsilon \rightarrow 0} \int_{0}^{\epsilon} f(t) \cdot \frac{1}{\epsilon} \, dt = \lim_{\epsilon \rightarrow 0} \frac{1}{\epsilon} \int_{0}^{\epsilon} f(t) \, dt = \lim_{\epsilon \rightarrow 0} \frac{1}{\epsilon} (\epsilon - 0) f(t*)$ for some point $t*$ s.t. $0 \leq t* \leq \epsilon$ (MVT for integrals)
    \item $ = \lim_{\epsilon \rightarrow 0} f(t*) = f(0)$ since $t* \rightarrow 0$ as $\epsilon \rightarrow 0$
    \item $\delta$ is a generalized function (aka distribution). It is also called the Dirac delta function
    \item We can also shift the impulse function i.e. $\delta (t-t_0) = 0$ if $t \neq t_0$
    \item If $f(t)$ is continuous on $a \leq t_0 < b$ , $\int_{a}^{b} f(t) \delta(t- t_0) \, dt = f(t_0)$
    \item Theorem $\mathcal{L} \{ \delta(t - t_0) \} = \int_{0}^{\infty} e^{-st} \delta(t-t_0) \, dt = f(t_0) = e^{-st_0}$
    \item Consider an undamped oscillator $y'' + y = I_0 \delta(t)$ $y(0) = 0$, $y'(0) = 0$ \begin{itemize}
        \item Laplace: $s^2 Y(s) + Y(s) = I_0 e^{-s \cdot 0} \implies Y(s) = I_0 \frac{1}{s^2+1}$
        \item Inverse LT: $y(t) = I_0 \sin (t)$
        \item However this gives $y'(0) = I_0$ but since we only consider $t \geq 0$, $y(t)$ is actually  $u_0 (t) I_0 \sin(t)$
        \item $\lim_{t \rightarrow 0^{-}} y'(t) = 0$
    \end{itemize}
\end{itemize}

\section{Convolution Integrals and Their Applications} \begin{itemize}
    \item If $f$ and $g$ are piecewise continuous on $[0, \infty)$, we define their convolution as $(f * g)(t) = \int_{0}^{t} f(t- \tau) g(\tau ) \, d \tau$
    \item Example: $f(t) = t$ and $g(t) = e^{-2t}$ \begin{itemize}
        \item $(f * g)(t) = \int_{0}^{t} (t - \tau) e^{-2 \tau} \, d \tau = [(t - \tau) (\frac{-1}{2}) e^{-2 \tau}]_{\tau = 0}^{\tau = t} + \int_{0}^{t} (-\frac{1}{2}) e^{-2 \tau} \, d \tau = \frac{t}{2} + \frac{1}{4} e^{-2t} - \frac{1}{4}$
    \end{itemize}
    \item Rules for Convolutions \begin{itemize}
        \item $f * g = g * f$
        \item $f * (g+h) = f*g + f*h$
        \item $f * 0 = 0$
        \item $(cf) * g = c(f * g)$
        \item Note: $f * 1 = f$
    \end{itemize}
    \item Proof that the convolution is commutative: \begin{itemize}
        \item $f * g = \int_{0}^{t} f(t - \tau) g(\tau) \, d \tau = - \int_{t}^{0} f(u) g(t-u) \, du = \int_{0}^{t} g(t-u) f(u) \, du = g * f$
    \end{itemize}
    \item Convolution Theorem: If $F(s) = \mathcal{L} \{ f(t) \}$ and $G(s) = \mathcal{L} \{ g(t) \}$ both exist for $s > a \geq 0$ then $F(s) G(s) = \mathcal{L} \{ (f*g) (t) \}$ and equivalently $\mathcal{L}^{-1} \{ F(s) G(s) \} = (f * g) (t)$
\end{itemize}

\section{Introduction to Partial Differential Equations}

\begin{itemize}
    \item The Heat Equation \begin{itemize}
        \item Consider a metal rod of length $L$. Let $u(x,t)$ be the temperature in the cross section at location $x$ and time $t$
        \item $u_t(x,t)$ represents the change in temperature over time for a fixed slice
        \item $u_x(x,t)$ represents the change over the rod for a fixed time
        \item $u_{xx}(x,t)$ represents how $u_x(t)$ changes over the rod for a fixed time
        \item The Heat Equation is given by $u_t = \alpha^2 u_{xx}$ where $a^2$ is the thermal diffusivity
    \end{itemize}
    \item Example: Solving the Heat Equation \begin{itemize}
        \item We can solve this by the seperation of variables
        \item Consider a metal rod with length 50cm, insulated on the ends and with an initial temp of 20 C throughout with the ends maintained at 0C
        \item The homogeneous problem is $u_t = \alpha^2 u_{xx}$ with $u(0, T) = 0$, $u(L,t) = 0$ for $t>0$ and $u(x,0) = 20$
        \item Assume that we can write $u(x,t) = X(x) T(t)$. This is a strong assumption since many functions cannot be written in this form e.g. $u(x,t) = \sin (xt)$
        \item Using this assumption, we can rewrite the homogeneous problem as $X(x) T'(t) = \alpha^2 X''(x) T(t)$, $X(0)T(t) = 0$, $X(L)T(t) = 0$ and $X(x)T(0) = 20$
        \item This leads to $X(0) = 0$ and $X(L) = 0$ since $T(t)$ cannot always be 0
        \item We rearrange the equation above as $\frac{T'(t)}{\alpha^2 T(t)} = \frac{X''(x)}{X(x)} = - \lambda$
        \item Since the two sides are equal, this expression cannot change over $x$ or $t$ so we let the expression be equal to $- \lambda$ where $\lambda$ is a constant
        \item We can find a solution for $X''(x)$ since $\frac{X''(x)}{X(x)} = - \lambda$ which has a solution $X(x) = c_1 \cos (\sqrt{\lambda} x) + c_2 \sin (\sqrt{\lambda} x)$ and using $X(0) = 0$ and $X(L) = 0$, we get $c_1 =0$ and $0 = c_2 \sin (\sqrt{\lambda} \cdot L)$ so that $\sqrt{\lambda} \cdot L = n \cdot \pi$. Equivalently $\lambda = \frac{n^2 \cdot \pi^2}{L^2}$
        \item We can similarly find a solution for $T(t)$ where the ODE is $\frac{T'(t)}{\alpha^2 T(t)} = - \lambda$
        \item $T'(t) = - \frac{n^2 \pi^2}{L^2} \alpha^2 T(t) \implies T(t) = e^{- \frac{n^2 \pi^2}{L^2} \alpha^2 t}$
        \item Combining into solutions of the heat equation: $u(x,t) = X(x) T(t) = \sin (\frac{n \pi}{L} x) e^{- \frac{n^2 \pi^2}{L^2} \alpha^2 t}$ (there can be any constant factor at the front)
        \item Fundamental solutions to the Heat Equation: $u_n (x,t) = \sin (\frac{n \pi x}{L}) e^{- \frac{n^2 \pi^2}{L^2} \alpha^2 t}$
        \item Theorem (Superposition Principle): If $a(x,t)$ and $b(x,t)$ solve the heat equation, $c_1 a(x,t) + c_2 b(x,t)$ solves the heat equation $\forall \, c_1, c_2 \in \mathbb{R}$
        \item General solution to the heat equation is $u(x,t) = \sum_{n=1}^{\infty} c_n \sin (\frac{n \pi x}{L}) e^{- \frac{n^2 \pi ^2 \alpha^2}{L^2} t}$
        \item Using the initial conditions, we have $20 = u(x,0) = \sum_{n=1}^{\infty} c_n \sin (\frac{n \pi x}{L})$
        \item This will work for $c_n = \frac{2}{L} \int_{0}^{L} 20 \cdot \sin (\frac{n \pi x}{L})$ (Fourier Series)
    \end{itemize}
\end{itemize}

\section{Fourier Series}

\begin{itemize}
    \item We define an inner product on $PC[a, b]$ by $<f, g> = \int_a^{b} f(x)g(x) \, dx$
    \item We say $f$ and $g$ are orthogonal if $<f,g> = 0$
    \item Consider $f(x)  =\cos(x)$ and $g(x) = \sin (x)$ in $PC[- \pi, \pi]$. $<\cos x, \sin x> = \int_{- \pi }^{\pi} \cos x \sin x \, dx = 0$ $\implies \cos x, \sin x$ are orthogonal on $PC [- \pi, \pi]$
    \item Consider $f(x) = \cos (x)$ and $g(x) = x^2$ in $PC[- \pi, \pi]$ $< \cos x, x^2 > = \int_{- \pi}^{\pi} \cos x x^2 \, dx = -4 \pi$
    \item Theorem: The following set of functions is an orthogonal family in $PC[-L, L]$: $\left\{ \frac{1}{2}, \sin (\frac{m \pi x}{L}), \cos (\frac{m \pi x}{L}): m = 1, 2, 3, \dots \right\}$
\end{itemize}


\end{document}
